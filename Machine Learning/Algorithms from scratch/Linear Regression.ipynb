{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import r2_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([0.8,1,1.2,1.4,1.6,1.8,2,2.2,2.4,2.6])\n",
    "Y = np.array([0.7,0.65,0.90,0.95,1.1,1.15,1.2,1.4,1.55,1.5])\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(X.shape[0],1)\n",
    "Y = Y.reshape(Y.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward Propogation\n",
    "alpha = 0.01\n",
    "epoch = 10000\n",
    "m = Y.size\n",
    "np.random.seed(123)\n",
    "theta = np.random.rand(2)\n",
    "theta = theta.reshape(theta.shape[0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GD(X, Y, theta, epoch, alpha):\n",
    "    past_cost = []\n",
    "    past_theta = [theta]\n",
    "    for i in range(epoch):\n",
    "        h_theta = np.dot(X, theta) # instead of theta you can also use past_theta[i]\n",
    "        error = h_theta - Y\n",
    "        cost = 1/(2*m)*np.dot(error.T, error)\n",
    "        past_cost.append(cost)\n",
    "        theta = theta - ( (1/m) * alpha * np.dot(X.T, error) ) \n",
    "        past_theta.append(theta)\n",
    "    return past_theta, past_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_theta, past_cost = GD(X, Y, theta, epoch, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_theta = past_theta[-1]\n",
    "best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_arr = np.asarray(past_cost)\n",
    "cost_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_arr = cost_arr.reshape((cost_arr.shape[0],1))\n",
    "cost_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(cost_arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Stopping Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GD_stop(X, Y, theta, epoch, alpha):\n",
    "    past_cost = []\n",
    "    past_theta = [theta] \n",
    "    for i in range(epoch):\n",
    "        h_theta = np.dot(X, theta)\n",
    "        error = h_theta - Y\n",
    "        cost = 1/(2*m)*np.dot(error.T, error)\n",
    "        past_cost.append(cost)\n",
    "        theta = theta - ( (1/m) * alpha * np.dot(X.T, error) ) \n",
    "        past_theta.append(theta)\n",
    "        if ( past_theta[i] == past_theta[i+1] ).all() : break\n",
    "    return past_theta, past_cost, i+1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "past_theta_gd, past_cost_gd, epoch_stop_gd = GD_stop(X, Y, theta, 50000, alpha)\n",
    "gd_time = time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_stop_gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_arr = np.asarray(past_cost_gd)\n",
    "cost_arr = cost_arr.reshape((cost_arr.shape[0],1))\n",
    "cost_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cost_arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch_GD(X, Y, theta, epoch, alpha, batch_size):\n",
    "    m = Y.size\n",
    "    past_cost = []\n",
    "    past_theta = [theta] \n",
    "    mini_batches = []\n",
    "    xy_combine = np.hstack([X,Y]) # to merge X and Y\n",
    "    np.random.shuffle(xy_combine)\n",
    "    no_of_batches = xy_combine.shape[0] // batch_size #Calculate the no. of complete batches possible\n",
    "    \n",
    "    \n",
    "    for i in range(no_of_batches): #Dividing the rest of the data as per the batch sizes and merge with the list of mini batches created\n",
    "        data = xy_combine[i*batch_size : (i+1)*batch_size]\n",
    "        y_mini = np.array(data[:,-1]).reshape((-1,1))\n",
    "        x_mini = np.array(data[:, :-1])\n",
    "        mini_batches.append((x_mini, y_mini))\n",
    "    \n",
    "    if xy_combine.shape[0] % batch_size != 0: # merging the one extra batch since its smaller than the batch size\n",
    "        data = xy_combine[-(xy_combine.shape[0] % batch_size):]\n",
    "        y_mini = np.array(data[:,-1]).reshape((-1,1))\n",
    "        x_mini = np.array(data[:, :-1])\n",
    "        mini_batches.append((x_mini, y_mini))\n",
    "        \n",
    "    for i in range(epoch):\n",
    "        for batch in  mini_batches:\n",
    "            h_theta = np.dot(batch[0], theta) # X-->batch[0]\n",
    "            error = h_theta - batch[1] #Y-->batch[1]\n",
    "            theta = theta - ( (1/m) * alpha * np.dot(batch[0].T, error) ) \n",
    "         \n",
    "        past_theta.append(theta)   #update the final theta of the batch\n",
    "        cost = 1/(2*m)*np.dot(error.T, error)\n",
    "        past_cost.append(cost)\n",
    "        if ( past_theta[i] == theta ).all() : break\n",
    "    return past_theta, past_cost, i+1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "start = time.time()\n",
    "past_theta_mb, past_cost_mb, epoch_stop_mb = mini_batch_GD(X, Y, theta, 50000, alpha, batch_size)\n",
    "mb_time = time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_arr = np.asarray(past_cost_mb)\n",
    "cost_arr = cost_arr.reshape((cost_arr.shape[0],1))\n",
    "cost_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cost_arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Gradient Descent and Mini_Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Time taken by :- \\nGradient Descent : {gd_time} \\nMini Batch : {mb_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Gradient Descent : \\nBest Theta : {past_theta_gd[-1]} \\nBest Cost : {past_cost_gd[-1]} \\nEpoch Stop : {epoch_stop_gd}')\n",
    "print(f'\\nMini_Batch : \\nBest Theta : {past_theta_mb[-1]} \\nBest Cost : {past_cost_mb[-1]} \\nEpoch Stop : {epoch_stop_mb}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linear_Regression(data, pred_col, alpha, epoch):\n",
    "    #Declaring X,y and theta\n",
    "    y = np.array(data[pred_col]).reshape((-1,1))\n",
    "    X = np.array(data.drop(pred_col, axis = 1))\n",
    "    X = np.c_[np.ones(X.shape[0]), X]\n",
    "    theta = np.random.rand(X.shape[1])\n",
    "    theta = theta.reshape(theta.shape[0], 1)\n",
    "    \n",
    "    #Gradient Descent\n",
    "    m = y.size\n",
    "    past_cost = []\n",
    "    for i in range(epoch):\n",
    "        predictions = np.dot(X,theta)\n",
    "        error = np.dot(X.T, (predictions-y))\n",
    "        descent = alpha * 1/m * error\n",
    "        theta-=descent # updated value of theta\n",
    "        \n",
    "        # Cost Computation\n",
    "        square_err = (predictions - y)**2\n",
    "        cost = 1/(m)*np.sum(square_err)\n",
    "        past_cost.append(cost) # Appending cost\n",
    "    return theta, past_cost, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "epoch = 10000\n",
    "data = pd.DataFrame(np.hstack([X,Y]))\n",
    "data.columns = ['1s','X', 'Y']\n",
    "\n",
    "start = time.time()\n",
    "theta_lr, past_cost_lr, predictions_lr = Linear_Regression(data,'Y',alpha, epoch)\n",
    "total_time_lr = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"h(x) = {str(round(theta_lr[0,0],2))}+{str(round(theta_lr[1,0],2))}x1{str(round(theta_lr[2,0],2))}x2\\nTime Taken to calculate Cost : {total_time_lr} \\nAccuracy : {round(r2_score(Y, predictions_lr) * 100 , 3)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_arr = np.asarray(past_cost_lr)\n",
    "cost_arr = cost_arr.reshape((cost_arr.shape[0],1))\n",
    "cost_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cost_arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
